services:
  neo4j:
    image: neo4j:5
    ports: 
      - "7474:7474"
      - "7687:7687"
    environment:
      NEO4J_AUTH: "neo4j/6xlBSIDu8Nc8gjXrpt3kNuwM7AZHGI3WJrfpN2fFDXE"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:7474/browser/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  api:
    build: .
    env_file:
      - .env
    depends_on:
      neo4j:
        condition: service_healthy
      ollama:
        condition: service_started     # wait for ollama before coach calls it
    environment:
      NEO4J_URI: "bolt://neo4j:7687"   # connect to the neo4j service from inside the container
      NEO4J_USER: "neo4j"
      NEO4J_PASSWORD: "6xlBSIDu8Nc8gjXrpt3kNuwM7AZHGI3WJrfpN2fFDXE"
      OLLAMA_BASE_URL: "http://ollama:11434"  # used inside coach.py
      DOND_DATA_DIR: "/app/deal_or_no_dialog/exported"
    ports: 
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - chroma_data:/app/chroma_db    # Persist ChromaDB data
      - ./deal_or_no_dialog/exported:/app/deal_or_no_dialog/exported:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  gradio:
    build: .
    container_name: gradio-ui
    ports:
      - "7860:7860"                 # browse at http://localhost:7860
    command: ["python", "-m", "app.gradio_ui"]
    depends_on:
      api:
        condition: service_healthy
      ollama:
        condition: service_started   # wait for ollama before trying to fetch models
    environment:
      - API_BASE_URL=http://api:8000 # Set for Gradio to connect to API service
      - OLLAMA_BASE_URL=http://ollama:11434 # Set for Gradio to fetch available models
      - DOND_DATA_DIR=/app/deal_or_no_dialog/exported
    volumes:
      - ./deal_or_no_dialog/exported:/app/deal_or_no_dialog/exported:ro

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ollama_models:/root/.ollama
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

volumes:
  neo4j_data:
  neo4j_logs:
  ollama_models:                      # Renamed for clarity
  chroma_data:                        # New volume for ChromaDB persistence

